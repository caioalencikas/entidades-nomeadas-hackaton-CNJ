{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cnj_assuntos.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-edced7805a80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0massuntos_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cnj_assuntos.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0massuntos_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cacalf\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cacalf\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cacalf\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cacalf\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cacalf\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cnj_assuntos.csv'"
     ]
    }
   ],
   "source": [
    "assuntos_df = pd.read_csv(\"dados/cnj_assuntos.csv\", sep=\";\")\n",
    "assuntos_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assuntos_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assuntos_df['cod_assunto'] = assuntos_df['cod_assunto'].astype(str)\n",
    "assuntos_df['cod_item_pai'] = assuntos_df['cod_item_pai'].astype(str)\n",
    "assuntos_df['artigo'] = assuntos_df['artigo'].astype(str)\n",
    "assuntos_df['dispositivo_legal'] = assuntos_df['dispositivo_legal'].astype(str)\n",
    "assuntos_df['nome'] = assuntos_df['nome'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assuntos_df[\"dispositivo_legal\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_assuntos_por_dispositivo = assuntos_df['dispositivo_legal'].value_counts().sort_values(ascending=False)\n",
    "total_assuntos_por_dispositivo.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispositivos_legais =assuntos_df['dispositivo_legal'].unique().tolist()\n",
    "dispositivos_legais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_document = \"\"\"\n",
    "EXMO(A). SR(A). DR(A). JUIZ(A). DE DIREITO DA 9ª VARA CÍVEL DA COMARCA GOI NIA -  GOIÁS.\n",
    "\n",
    "APELANTE:      AMADA CARMO    \n",
    "APELADA:        BANCO GENERAL MOTORS  S.A .\n",
    "AUTOS Nº:       200603762900\n",
    "NATUREZA:     AÇÃO ORDINÁRIA REVISIONAL DE CONTRATO (FINANCIAMENTO DE VEÍCULO)\n",
    "ORIGEM:           9ª  VARA  CÍVEL DE GOI NIA - GOIÁS.\n",
    "\n",
    "                    AMADA CARMO,  via de seu procurador e advogado infra-assinado, ambos qualificados nos mesmos autos, movendo AÇÃO ORDINÁRIA REVISIONAL DE CONTRATO     DE (FINANCIAMENTO DE VEÍCULO), em face do BANCO GENERAL MOTORS S.A, também qualificado nos mesmos autos, vem perante V. Exa., respeitosamente, não se conformando data máxima vênia, com a r. sentença proferida pelo magistrado da 9ª Vara Civil da Comarca de Goiânia - Goiás, interpor RECURSO DE APELAÇÃO  para o Egrégio Tribunal de Justiça do Estado de Goiás, fazendo-o e fundamentado nos termos do art. 513 e seguintes do Código de Processo Civil,  ante as razões a seguir alinhadas.\n",
    "\n",
    "                    Por tempestivo o presente recurso de Apelação, requer seja o mesmo admitido e provido  por esta Corte Superior de Justiça, nos termos da fundamentação a seguir destacada.\n",
    "\n",
    "                    Termos em que,\n",
    "                    Pede Deferimento\n",
    "                    Goiânia(GO), 01 de Novembro  de 2007 \n",
    "\n",
    "Pp/\n",
    "EXMO. SR. DR. DESEMBARGADOR PRESIDENTE DO EGRÉGIO TRIBUNAL DE JUSTIÇA DO ESTADO DE GOIÁS.  \n",
    "\n",
    "APELANTE:      AMADA CARMO    \n",
    "APELADA:        BANCO GENERAL MOTORS  S.A .\n",
    "AUTOS Nº:       200603762900\n",
    "NATUREZA:     AÇÃO ORDINÁRIA REVISIONAL DE CONTRATO (FINANCIAMENTO DE VEÍCULO)\n",
    "ORIGEM:           9ª  VARA  CÍVEL DE GOI NIA - GOIÁS.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "             RAZÕES DA APELAÇÃO\n",
    "                \n",
    "Colendo Tribunal:\n",
    "\n",
    "                Nobre Relator,\n",
    "\n",
    "\n",
    "                Preclaros componentes desta Ilustrada corte superior de Justiça, a r. sentença recorrida não fez no caso vertente a verdadeira justiça, vez que  desprovida de fundamentação jurídica, a rigor, o decisum proferido pelo nobre magistrado singular diverge do melhor direito, visto que JULGOU IMPROCEDENTE  os pedidos constante do pleito vestibular sob o seguinte argumento:: “. . . Cuidam os presentes autos de pedido de revisão de contrato cumulado com antecipação de tutela, onde o requerente alega que entabulou contrato de cheque especial e empréstimo (grifo nosso) com o requerido, tendo efetuado o pagamento a maior em razão dos juros abusivos e encargos indevidos, violando desta forma a função social do contrato, bem como o Código de Defesa do Consumidor, fato que lhe causou prejuízo na avenca.\n",
    "                     A sentença monocrática lançada às laudas das (fls. 148 a 155) dos autos, milita em erro, a rigor, a apelante não contratou com o banco/Apelado contrato de abertura de crédito em conta corrente (cheque especial) nem fez com o mesmo empréstimo bancário, mas sim contratou um financiamento na modalidade “Cédula de Crédito Bancário” com alienação fiduciária, para aquisição de um veículo automotor, conforme bastante explanada na vestibular.\n",
    "\n",
    "                    Nesta corrente, o decisum faz tabula rasa da lei, vez que o mútuo chamado “cheque especial” e contrato de mútuo detém legislação diferenciada da modalidade do crédito chamado “cédula de crédito bancário” com alienação fiduciária, alem do que o contrato de abertura de crédito (cheque especial) não se confunde com contrato de financiamento ou cédula de crédito bancário, assim também já posicionou no Egrégio Tribunal de Justiça do  Estado de Goiás, senão vejamos o seguinte aresto, verbis: \n",
    "                “EXECUÇÃO. EMBARGOS. CÉDULA DE CRÉDITO BANCÁRIO. NOTA PROMISSÓRIA. INCONSTITUCIONALIDADE. CÁLCULO. I – SÃO INCONFUNDÍVEIS A CÉDULA DE CRÉDITO BANCÁRIO E CONTRATO DE ABERTURA DE CRÉDITO EM CONTA CORRENTE – CHEQUE ESPECIAL – A PRIMEIRA CONSISTE EM EMPRESTIMO, COM CONDIÇÕES ESPECÍFICAS, QUE É CREDITADO NA INTEGRA NA CONTA DO TOMADOR, O SEGUNDO PERMITE O CORRENTISTA SAQUES DE VALORES ATÉ DETERMINADO LIMITE, SEM SE EFETUAR O CRÉDITO DESTE EM SUA CONTA, MAS RESPONSABILIZANDO-SE ELE PELA REPOSIÇÃO DO VALOR SACADO E DOS ENCARGOS. A CÉDULA DE CRÉDITO BANCÁRIO, COMPORTA OPERAÇÕES DIVERSAS E POR DISPOSIÇÕES LEGAIS É TÍTULO EXECUTIVO EXTRAJUCIDIAL. II – O JULGADOR MONOCRÁTICO PODE RECUSAR-SE A APLICAR A LEI QUE CONSIDERAR INCONSTITUCIONAL MAS NÃO É DE SEU COMPETÊNCIA A DECLARAÇÃO DESSA INCONSTITUCIONALIDADE. III – SE O CÁLCULO APRESENTADO PELO EXEQUENTE NÃO OFENDE A LEI NEM O CONTRATO É, CONFRONTADO COM AS DISPOSIÇÕES DESTE, É FAVORÁVEL AO DEVEDOR, CONFIRMA-SE ELE. IV – RECURSO DE APELAÇÃO CONHECIDO E PROVIDO, DECISÃO UNÁNIME” (2ª Câmara Civil, DJ-14376  de 20.10.2004, ACÓRDÃO, 16.09.2004, Dês. MARÍLIA JUNGMANN SANTANA, 67585-9/188,  APELAÇÃO CÍVIL.\n",
    " \n",
    "                     Nesta corrente, a sentença foi proferida em erro e sua nulidade é pacificada. De outro lado, embora o julgador monocrático tenha debatido apenas sobre a limitação de juros, deixou de apreciar acerca de outras questões relevantes e fundamentais acerca do pedido, como se pode observar: comissão de permanência, multa moratória e capitalização de juros. Neste entendimento, estando o decisum divergente do teor contratado e, omissa em apreciar na integralidade as questões dos pedidos constantes da vestibular, torna a r. sentença viciada e sua nulidade há de ser declarada.\n",
    " \n",
    "                De outro lado, o decisum colacionou com bastante veemência a limitação de juros ante o art. 192, §  III, da Constituição Federal, e ao final de sua dissertação aduz que os empréstimos bancários de uma maneira geral estão sujeitos ao Código de Defesa do Consumidor e que por sua vez os juros para se tornarem abusivos devem discrepar, de modo substancial, da média do mercado e da praça do empréstimo, razão porque julgou improcedente os pedidos constantes do pleito vestibular.  \n",
    "\n",
    "              Neste prisma, a Apelante pleiteia, na verdade, que seja revisado seu contrato com base no CDC e não /pelo art. 192, § 3º da CF muito menos pela EC 40/2003. Não investe em juízo em aventura, se o nobre magistrado parasse um pouco para averiguar os pedidos não teria muita dificuldade de verificar os  abusos cometidos pela instituição Financeira, não incitaria em dizer que a boa-fé objetiva seria do  agente financeiro, comumente dentre as relações negociais, engoda em contrato de adesão juros maquiados, cumulados com outros encargos ilegais o que gera um fator de lucratividade fora do normal e do comum. \n",
    "\n",
    "                Ressaltando-se, todavia, que o entendimento do nobre magistrado a quo, no que pertine a verificação dos juros não discreparem da média do mercado, s.m.j de V Exa. os juros  nominais mensais  unificados com a correção financeira do CDI  mensalmente para cálculos e cobrança ou capitalização mensalmente, encargos de juros equivalentes produzem resultados da conta em regime diferentes, em total afronta ao nosso ordenamento jurídico (artigo 6.º - do Decreto 22.626/33, combinado com o artigo 591 do CCB-2002 e artigo 52-inc. II – da Lei 8.078/90), e ainda:\n",
    "          O nosso ordenamento jurídico proíbe a aplicação de encargos de juros unificados com a correção (artigo 1.º - § 2.º - da Lei 8.383/91); \n",
    "\n",
    "       Os juros nominais mensais são secundários, para efeito estatístico, e excepcionalmente podem ser aplicados, desde que, o resultado da conta seja o mesmo de quando aplica-se encargos de juros efetivos fixos anuais, calculados e cobrados ou capitalizados anualmente (artigo 6.º - do Decreto 22.626/33);\n",
    "\n",
    "       No presente caso a cláusula de juros efetivos fixos anuais unificados com a correção financeira do CDI de 21,60% ao ano para cálculos e cobrança ou capitalização anualmente e  de juros nominais mensais unificados com a correção financeira do CDI de 1,81% ao mês não são equivalentes, portanto a cláusula contratual de juros é ambígua, devendo ser interpretada de maneira mais favorável ao Aderente/Apelante (artigo 54 §§ 1.º e 2.º da Lei 8.078/90 e artigo 423 do CCB-2002), e ainda:\n",
    "     \n",
    "    Quanto a correção monetária, no presente caso cabe a aplicação da correção monetária do INPC ou da IRP/TR nos meses que for mais benéfico para a Autor/Aderente/Apelante, para corrigir o saldo devedor e os valores das prestações mensais;\n",
    "     \n",
    "          De sorte que, quando no contrato existirem cláusulas abusivas e iníquas, nos termos do art. 51 do Código de Defesa do Consumidor, são nulas de pleno direito, e podem ser suscitadas e revisadas a qualquer tempo. Ademais, em matéria de juros, os artigos 406, 591 e 2035, parágrafo único da Lei 10.406/02, combinados com os artigos 39, § 4º., da Lei 9.250/95, sugerem a adoção de índices não superiores a taxa referencial do Sistema de Liquidação de Custódia – SELIC – ou mesmo sua taxação em 1% ao mês, conforme dispõe  o art. 161. § 1º do Código Tribunal Nacional.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex_patterns = {\n",
    "    \"lei\":[r\"(?i)Lei\\s\\d*\\.?\\d*\\/\\d+\",r\"L\\s\\d*\\.?\\d*\\/\\d+\",r\"Lei Federal\\s\\d*\\.?\\d*\\/\\d+\",r\"Decreto de Lei \\s\\d*\\.?\\d*\\/\\d+\"],\n",
    "    \"artigo\":[r\"(?i)artig\\w+\\s\\d*\",r\"(?i)art.\\s\\d*\"],    \n",
    "    \"dispositivo\":[],\n",
    "    \"peticaoInicial\": [r\"(?i)CPF\",r\"(?i)CNPJ\",r\"(?i)\\s+RG\",r\"(?i)Solteir\\w\",r\"(?i)Casad\\w\"\n",
    "                       ,r\"(?i)Divorciad\\w\",r\"(?i)Vi\\wv\\w\",r\"(?i)Av.\\s\\d*\"\n",
    "                       ,r\"(?i)Rua\",r\"(?i)Endereço\",r\"(?i)Reside\\w*\",r\"(?i)Domicil\\w*\"]\n",
    "}\n",
    "\n",
    "regex_estado_civil = [r\"(?i)Solteir\\w\",r\"(?i)Casad\\w\",r\"(?i)Divorciad\\w\",r\"(?i)Vi\\wv\\w\"]\n",
    "regex_cpf = [r\"(?i)CPF\",r\"(?i)CNPJ\"]\n",
    "regex_rg = [r\"(?i)\\s+RG\"]\n",
    "regex_endereco = [r\"(?i)Av.\\s\\d*\",r\"(?i)Rua\",r\"(?i)Endereço\",r\"(?i)Reside\\w*\",r\"(?i)Domicil\\w*\"]\n",
    "\n",
    "separadores = [\";\",\",\",\" e \"]\n",
    "for separador in separadores:\n",
    "    for dl_nome in dispositivos_legais:\n",
    "        if separador in dl_nome:\n",
    "            dl_nomes = dl_nome.split(separador)\n",
    "            for dl in dl_nomes:\n",
    "                dl = dl.strip()\n",
    "                if(len(dl) > 2):\n",
    "                    regex_patterns[\"dispositivo\"].append(rf\"{dl}\")\n",
    "        else:\n",
    "            dl_nome = dl_nome.strip()\n",
    "            if(len(dl_nome) > 2):\n",
    "                regex_patterns[\"dispositivo\"].append(f\"{dl_nome}\")\n",
    "            \n",
    "regex_patterns[\"dispositivo\"] = list(set(regex_patterns[\"dispositivo\"]))\n",
    "regex_patterns[\"dispositivo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "    \n",
    "def find_pattern_mentions(regex_pattern, input_str):\n",
    "    mentions = []\n",
    "    matches = re.finditer(regex_pattern, input_str, re.MULTILINE)\n",
    "\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "#         print (\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n",
    "        mentions.append(match.group())\n",
    "        \n",
    "    return mentions\n",
    "\n",
    "def parse_legal_entities(_input_text):\n",
    "\n",
    "    resultados = {\"artigo\":[],\"lei\":[],\"dispositivo\":[], \"peticaoInicial\":[]}\n",
    "    \n",
    "    \n",
    "    for categoria_de_regra in regex_patterns.keys():\n",
    "#         print(\"procurar por padrões de : \", categoria_de_regra)\n",
    "        for regra in regex_patterns[categoria_de_regra]:\n",
    "            try:\n",
    "                found_mentions = find_pattern_mentions(regra, _input_text)\n",
    "                if(len(found_mentions) > 0):\n",
    "                    resultados[categoria_de_regra].append(found_mentions)\n",
    "            except:\n",
    "#                 print(\"regra inválida =>\", regra)\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "    def flatten_list(_list):\n",
    "        return list(itertools.chain(*_list))\n",
    "\n",
    "    for _ in [\"artigo\",\"lei\",\"dispositivo\", \"peticaoInicial\"]:\n",
    "        resultados[_] = flatten_list(resultados[_])\n",
    "\n",
    "    return resultados    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_legal_entities(sample_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "lang_model_name = \"pt_core_news_sm\"\n",
    "# download Portuguese model from spacy\n",
    "try:\n",
    "    spacy.load(lang_model_name)\n",
    "except:\n",
    "    spacy.cli.download(lang_model_name)\n",
    "    \n",
    "nlp = spacy.load(lang_model_name)\n",
    "doc = nlp(sample_document)\n",
    "for sent in doc.sents:\n",
    "    sentence = sent.text.strip()\n",
    "    print(\"FRASE------->\",sentence) \n",
    "    legal_entities = parse_legal_entities(sentence)\n",
    "    if(len(legal_entities[\"artigo\"]) > 0 or len(legal_entities[\"lei\"]) > 0 or len(legal_entities[\"dispositivo\"]) > 0):\n",
    "        print(\"ENTIDADES--->\",legal_entities)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_final = pd.DataFrame(data={'Frase': '', 'Artigo': '', 'Lei': ''\n",
    "                                     , 'Dispositivo': '', 'Petição Inicial': []})\n",
    "resultado_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filename1 = 'dados/arquivo1.doc'\n",
    "filename2 = 'dados/arquivo2.doc'\n",
    "filename3 = 'dados/arquivo3.doc'\n",
    "filename4 = 'dados/arquivo4.doc'\n",
    "filename5 = 'dados/arquivo5.doc'\n",
    "filename6 = 'dados/arquivo6.doc'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file1 = open(filename1, 'r', encoding=\"ISO-8859-1\")\n",
    "doc1 = ''\n",
    "for line in file1:\n",
    "    doc1 += line.rstrip('\\n')\n",
    "    \n",
    "file1.close()\n",
    "document1 = nlp(doc1)\n",
    "\n",
    "# check petição inicial\n",
    "c = 0\n",
    "peticoes = set()\n",
    "for sent in document1.sents:\n",
    "    sentence = sent.text.strip()\n",
    "    legal_entities = parse_legal_entities(sentence)\n",
    "    if c >= 5:\n",
    "        break\n",
    "    if(len(legal_entities[\"artigo\"]) > 0 or len(legal_entities[\"lei\"]) > 0 \n",
    "       or len(legal_entities[\"dispositivo\"]) > 0 or len(legal_entities[\"peticaoInicial\"]) > 0):\n",
    "        for peticao in legal_entities[\"peticaoInicial\"]:\n",
    "            peticoes.add(peticao.lower())\n",
    "        c += 1\n",
    "\n",
    "endereco = 0\n",
    "estado_civil = 0\n",
    "rg = 0\n",
    "cpf = 0\n",
    "for peticao in peticoes:\n",
    "    for pattern in regex_endereco:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                endereco = 1\n",
    "    for pattern in regex_estado_civil:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                estado_civil = 1\n",
    "    for pattern in regex_rg:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                rg = 1\n",
    "    for pattern in regex_cpf:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                cpf = 1\n",
    "\n",
    "requisitos_encontrados = endereco + estado_civil + rg + cpf\n",
    "\n",
    "# extração artigos, leis e dispositivos\n",
    "frases = []\n",
    "artigos = []\n",
    "leis = []\n",
    "dispositivos = []\n",
    "peticao_inicial = []\n",
    "\n",
    "if requisitos_encontrados >= 3:\n",
    "    for sent in document1.sents:\n",
    "        sentence = sent.text.strip()\n",
    "        #print(\"FRASE------->\",sentence) \n",
    "        legal_entities = parse_legal_entities(sentence)\n",
    "        if len(legal_entities[\"artigo\"]) > 0 and (len(legal_entities[\"lei\"]) > 0 \n",
    "           or len(legal_entities[\"dispositivo\"]) > 0):\n",
    "            print(\"FRASE------->\",sentence)\n",
    "            print(\"ENTIDADES--->\",legal_entities)\n",
    "            print()\n",
    "            \n",
    "            frases.append(sentence)\n",
    "            artigos.append(legal_entities[\"artigo\"])\n",
    "            leis.append(legal_entities[\"lei\"])\n",
    "            dispositivos.append(legal_entities[\"dispositivo\"])\n",
    "            peticao_inicial.append(legal_entities[\"peticaoInicial\"])\n",
    "            \n",
    "            resultado = pd.DataFrame(data={'Frase': frases, 'Artigo': artigos\n",
    "                                           , 'Lei': leis\n",
    "                                           , 'Dispositivo': dispositivos\n",
    "                                           , 'Petição Inicial': peticao_inicial})\n",
    "resultado.to_csv('arquivo1.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file2 = open(filename2, 'r', encoding=\"ISO-8859-1\")\n",
    "doc2 = ''\n",
    "for line in file2:\n",
    "    doc2 += line.rstrip('\\n')\n",
    "    \n",
    "file2.close()\n",
    "document2 = nlp(doc2)\n",
    "\n",
    "# check petição inicial\n",
    "c = 0\n",
    "peticoes = set()\n",
    "for sent in document2.sents:\n",
    "    sentence = sent.text.strip()\n",
    "    legal_entities = parse_legal_entities(sentence)\n",
    "    if c >= 5:\n",
    "        break\n",
    "    if(len(legal_entities[\"artigo\"]) > 0 or len(legal_entities[\"lei\"]) > 0 \n",
    "       or len(legal_entities[\"dispositivo\"]) > 0 or len(legal_entities[\"peticaoInicial\"]) > 0):\n",
    "        for peticao in legal_entities[\"peticaoInicial\"]:\n",
    "            peticoes.add(peticao.lower())\n",
    "        c += 1\n",
    "\n",
    "endereco = 0\n",
    "estado_civil = 0\n",
    "rg = 0\n",
    "cpf = 0\n",
    "for peticao in peticoes:\n",
    "    for pattern in regex_endereco:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                endereco = 1\n",
    "    for pattern in regex_estado_civil:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                estado_civil = 1\n",
    "    for pattern in regex_rg:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                rg = 1\n",
    "    for pattern in regex_cpf:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                cpf = 1\n",
    "\n",
    "requisitos_encontrados = endereco + estado_civil + rg + cpf\n",
    "\n",
    "# extração artigos, leis e dispositivos\n",
    "frases = []\n",
    "artigos = []\n",
    "leis = []\n",
    "dispositivos = []\n",
    "peticao_inicial = []\n",
    "\n",
    "if requisitos_encontrados >= 3:\n",
    "    for sent in document2.sents:\n",
    "        sentence = sent.text.strip()\n",
    "        #print(\"FRASE------->\",sentence) \n",
    "        legal_entities = parse_legal_entities(sentence)\n",
    "        if len(legal_entities[\"artigo\"]) > 0 and (len(legal_entities[\"lei\"]) > 0 \n",
    "           or len(legal_entities[\"dispositivo\"]) > 0):\n",
    "            print(\"FRASE------->\",sentence)\n",
    "            print(\"ENTIDADES--->\",legal_entities)\n",
    "            print()\n",
    "            \n",
    "            frases.append(sentence)\n",
    "            artigos.append(legal_entities[\"artigo\"])\n",
    "            leis.append(legal_entities[\"lei\"])\n",
    "            dispositivos.append(legal_entities[\"dispositivo\"])\n",
    "            peticao_inicial.append(legal_entities[\"peticaoInicial\"])\n",
    "            \n",
    "            resultado = pd.DataFrame(data={'Frase': frases, 'Artigo': artigos\n",
    "                                           , 'Lei': leis\n",
    "                                           , 'Dispositivo': dispositivos\n",
    "                                           , 'Petição Inicial': peticao_inicial})\n",
    "resultado.to_csv('arquivo2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file3 = open(filename3, 'r', encoding=\"ISO-8859-1\")\n",
    "doc3 = ''\n",
    "for line in file3:\n",
    "    doc3 += line.rstrip('\\n')\n",
    "    \n",
    "file3.close()\n",
    "document3 = nlp(doc3)\n",
    "\n",
    "# check petição inicial\n",
    "c = 0\n",
    "peticoes = set()\n",
    "for sent in document3.sents:\n",
    "    sentence = sent.text.strip()\n",
    "    legal_entities = parse_legal_entities(sentence)\n",
    "    if c >= 5:\n",
    "        break\n",
    "    if(len(legal_entities[\"artigo\"]) > 0 or len(legal_entities[\"lei\"]) > 0 \n",
    "       or len(legal_entities[\"dispositivo\"]) > 0 or len(legal_entities[\"peticaoInicial\"]) > 0):\n",
    "        for peticao in legal_entities[\"peticaoInicial\"]:\n",
    "            peticoes.add(peticao.lower())\n",
    "        c += 1\n",
    "\n",
    "endereco = 0\n",
    "estado_civil = 0\n",
    "rg = 0\n",
    "cpf = 0\n",
    "for peticao in peticoes:\n",
    "    for pattern in regex_endereco:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                endereco = 1\n",
    "    for pattern in regex_estado_civil:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                estado_civil = 1\n",
    "    for pattern in regex_rg:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                rg = 1\n",
    "    for pattern in regex_cpf:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                cpf = 1\n",
    "\n",
    "requisitos_encontrados = endereco + estado_civil + rg + cpf\n",
    "\n",
    "# extração artigos, leis e dispositivos\n",
    "frases = []\n",
    "artigos = []\n",
    "leis = []\n",
    "dispositivos = []\n",
    "peticao_inicial = []\n",
    "\n",
    "if requisitos_encontrados >= 3:\n",
    "    for sent in document3.sents:\n",
    "        sentence = sent.text.strip()\n",
    "        #print(\"FRASE------->\",sentence) \n",
    "        legal_entities = parse_legal_entities(sentence)\n",
    "        if len(legal_entities[\"artigo\"]) > 0 and (len(legal_entities[\"lei\"]) > 0 \n",
    "           or len(legal_entities[\"dispositivo\"]) > 0):\n",
    "            print(\"FRASE------->\",sentence)\n",
    "            print(\"ENTIDADES--->\",legal_entities)\n",
    "            print()\n",
    "            \n",
    "            frases.append(sentence)\n",
    "            artigos.append(legal_entities[\"artigo\"])\n",
    "            leis.append(legal_entities[\"lei\"])\n",
    "            dispositivos.append(legal_entities[\"dispositivo\"])\n",
    "            peticao_inicial.append(legal_entities[\"peticaoInicial\"])\n",
    "            \n",
    "            resultado = pd.DataFrame(data={'Frase': frases, 'Artigo': artigos\n",
    "                                           , 'Lei': leis\n",
    "                                           , 'Dispositivo': dispositivos\n",
    "                                           , 'Petição Inicial': peticao_inicial})\n",
    "resultado.to_csv('arquivo3.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file4 = open(filename4, 'r', encoding=\"ISO-8859-1\")\n",
    "doc4 = ''\n",
    "for line in file4:\n",
    "    doc4 += line.rstrip('\\n')\n",
    "    \n",
    "file4.close()\n",
    "document4 = nlp(doc4)\n",
    "\n",
    "# check petição inicial\n",
    "c = 0\n",
    "peticoes = set()\n",
    "for sent in document4.sents:\n",
    "    sentence = sent.text.strip()\n",
    "    legal_entities = parse_legal_entities(sentence)\n",
    "    if c >= 5:\n",
    "        break\n",
    "    if(len(legal_entities[\"artigo\"]) > 0 or len(legal_entities[\"lei\"]) > 0 \n",
    "       or len(legal_entities[\"dispositivo\"]) > 0 or len(legal_entities[\"peticaoInicial\"]) > 0):\n",
    "        for peticao in legal_entities[\"peticaoInicial\"]:\n",
    "            peticoes.add(peticao.lower())\n",
    "        c += 1\n",
    "\n",
    "endereco = 0\n",
    "estado_civil = 0\n",
    "rg = 0\n",
    "cpf = 0\n",
    "for peticao in peticoes:\n",
    "    for pattern in regex_endereco:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                endereco = 1\n",
    "    for pattern in regex_estado_civil:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                estado_civil = 1\n",
    "    for pattern in regex_rg:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                rg = 1\n",
    "    for pattern in regex_cpf:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                cpf = 1\n",
    "\n",
    "requisitos_encontrados = endereco + estado_civil + rg + cpf\n",
    "\n",
    "# extração artigos, leis e dispositivos\n",
    "frases = []\n",
    "artigos = []\n",
    "leis = []\n",
    "dispositivos = []\n",
    "peticao_inicial = []\n",
    "\n",
    "if requisitos_encontrados >= 3:\n",
    "    for sent in document4.sents:\n",
    "        sentence = sent.text.strip()\n",
    "        #print(\"FRASE------->\",sentence) \n",
    "        legal_entities = parse_legal_entities(sentence)\n",
    "        if len(legal_entities[\"artigo\"]) > 0 and (len(legal_entities[\"lei\"]) > 0 \n",
    "           or len(legal_entities[\"dispositivo\"]) > 0):\n",
    "            print(\"FRASE------->\",sentence)\n",
    "            print(\"ENTIDADES--->\",legal_entities)\n",
    "            print()\n",
    "            \n",
    "            frases.append(sentence)\n",
    "            artigos.append(legal_entities[\"artigo\"])\n",
    "            leis.append(legal_entities[\"lei\"])\n",
    "            dispositivos.append(legal_entities[\"dispositivo\"])\n",
    "            peticao_inicial.append(legal_entities[\"peticaoInicial\"])\n",
    "            \n",
    "            resultado = pd.DataFrame(data={'Frase': frases, 'Artigo': artigos\n",
    "                                           , 'Lei': leis\n",
    "                                           , 'Dispositivo': dispositivos\n",
    "                                           , 'Petição Inicial': peticao_inicial})\n",
    "resultado.to_csv('arquivo4.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file5 = open(filename5, 'r', encoding=\"ISO-8859-1\")\n",
    "doc5 = ''\n",
    "for line in file5:\n",
    "    doc5 += line.rstrip('\\n')\n",
    "    \n",
    "file5.close()\n",
    "document5 = nlp(doc5)\n",
    "\n",
    "# check petição inicial\n",
    "c = 0\n",
    "peticoes = set()\n",
    "for sent in document5.sents:\n",
    "    sentence = sent.text.strip()\n",
    "    legal_entities = parse_legal_entities(sentence)\n",
    "    if c >= 5:\n",
    "        break\n",
    "    if(len(legal_entities[\"artigo\"]) > 0 or len(legal_entities[\"lei\"]) > 0 \n",
    "       or len(legal_entities[\"dispositivo\"]) > 0 or len(legal_entities[\"peticaoInicial\"]) > 0):\n",
    "        for peticao in legal_entities[\"peticaoInicial\"]:\n",
    "            peticoes.add(peticao.lower())\n",
    "        c += 1\n",
    "\n",
    "endereco = 0\n",
    "estado_civil = 0\n",
    "rg = 0\n",
    "cpf = 0\n",
    "for peticao in peticoes:\n",
    "    for pattern in regex_endereco:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                endereco = 1\n",
    "    for pattern in regex_estado_civil:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                estado_civil = 1\n",
    "    for pattern in regex_rg:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                rg = 1\n",
    "    for pattern in regex_cpf:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                cpf = 1\n",
    "\n",
    "requisitos_encontrados = endereco + estado_civil + rg + cpf\n",
    "\n",
    "# extração artigos, leis e dispositivos\n",
    "frases = []\n",
    "artigos = []\n",
    "leis = []\n",
    "dispositivos = []\n",
    "peticao_inicial = []\n",
    "\n",
    "if requisitos_encontrados >= 3:\n",
    "    for sent in document5.sents:\n",
    "        sentence = sent.text.strip()\n",
    "        #print(\"FRASE------->\",sentence) \n",
    "        legal_entities = parse_legal_entities(sentence)\n",
    "        if len(legal_entities[\"artigo\"]) > 0 and (len(legal_entities[\"lei\"]) > 0 \n",
    "           or len(legal_entities[\"dispositivo\"]) > 0):\n",
    "            print(\"FRASE------->\",sentence)\n",
    "            print(\"ENTIDADES--->\",legal_entities)\n",
    "            print()\n",
    "            \n",
    "            frases.append(sentence)\n",
    "            artigos.append(legal_entities[\"artigo\"])\n",
    "            leis.append(legal_entities[\"lei\"])\n",
    "            dispositivos.append(legal_entities[\"dispositivo\"])\n",
    "            peticao_inicial.append(legal_entities[\"peticaoInicial\"])\n",
    "            \n",
    "            resultado = pd.DataFrame(data={'Frase': frases, 'Artigo': artigos\n",
    "                                           , 'Lei': leis\n",
    "                                           , 'Dispositivo': dispositivos\n",
    "                                           , 'Petição Inicial': peticao_inicial})\n",
    "resultado.to_csv('arquivo5.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file6 = open(filename6, 'r', encoding=\"ISO-8859-1\")\n",
    "doc6 = ''\n",
    "for line in file6:\n",
    "    doc6 += line.rstrip('\\n')\n",
    "    \n",
    "file6.close()\n",
    "document6 = nlp(doc6)\n",
    "\n",
    "# check petição inicial\n",
    "c = 0\n",
    "peticoes = set()\n",
    "for sent in document6.sents:\n",
    "    sentence = sent.text.strip()\n",
    "    legal_entities = parse_legal_entities(sentence)\n",
    "    if c >= 5:\n",
    "        break\n",
    "    if(len(legal_entities[\"artigo\"]) > 0 or len(legal_entities[\"lei\"]) > 0 \n",
    "       or len(legal_entities[\"dispositivo\"]) > 0 or len(legal_entities[\"peticaoInicial\"]) > 0):\n",
    "        for peticao in legal_entities[\"peticaoInicial\"]:\n",
    "            peticoes.add(peticao.lower())\n",
    "        c += 1\n",
    "\n",
    "endereco = 0\n",
    "estado_civil = 0\n",
    "rg = 0\n",
    "cpf = 0\n",
    "for peticao in peticoes:\n",
    "    for pattern in regex_endereco:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                endereco = 1\n",
    "    for pattern in regex_estado_civil:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                estado_civil = 1\n",
    "    for pattern in regex_rg:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                rg = 1\n",
    "    for pattern in regex_cpf:\n",
    "        for found in re.findall(pattern, peticao):\n",
    "            if found == peticao:\n",
    "                cpf = 1\n",
    "\n",
    "requisitos_encontrados = endereco + estado_civil + rg + cpf\n",
    "\n",
    "# extração artigos, leis e dispositivos\n",
    "frases = []\n",
    "artigos = []\n",
    "leis = []\n",
    "dispositivos = []\n",
    "peticao_inicial = []\n",
    "\n",
    "if requisitos_encontrados >= 3:\n",
    "    for sent in document6.sents:\n",
    "        sentence = sent.text.strip()\n",
    "        #print(\"FRASE------->\",sentence) \n",
    "        legal_entities = parse_legal_entities(sentence)\n",
    "        if len(legal_entities[\"artigo\"]) > 0 and (len(legal_entities[\"lei\"]) > 0 \n",
    "           or len(legal_entities[\"dispositivo\"]) > 0):\n",
    "            print(\"FRASE------->\",sentence)\n",
    "            print(\"ENTIDADES--->\",legal_entities)\n",
    "            print()\n",
    "            \n",
    "            frases.append(sentence)\n",
    "            artigos.append(legal_entities[\"artigo\"])\n",
    "            leis.append(legal_entities[\"lei\"])\n",
    "            dispositivos.append(legal_entities[\"dispositivo\"])\n",
    "            peticao_inicial.append(legal_entities[\"peticaoInicial\"])\n",
    "            \n",
    "            resultado = pd.DataFrame(data={'Frase': frases, 'Artigo': artigos\n",
    "                                           , 'Lei': leis\n",
    "                                           , 'Dispositivo': dispositivos\n",
    "                                           , 'Petição Inicial': peticao_inicial})\n",
    "resultado.to_csv('arquivo6.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
